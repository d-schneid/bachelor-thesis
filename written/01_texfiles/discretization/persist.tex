\subsection{Persist} \label{persist_modifications}
Similar to the \ac{aSAX}, the Persist discretization algorithm takes the time series data into account for discretization and computes adapted breakpoints, respectively. However, these adapted breakpoints are not computed based on the k-means clustering algorithm, but on a decision criterion called persistence score \cite{Persist}. \newline
Moreover, in its unmodified version, the Persist applies amplitude discretization to the original standardized time series instead of the \ac{PAA} representation to obtain the discretized Persist representation \cite{Persist}. But, modifications to use the \ac{PAA} representation are possible as described below.
\subsection*{Main Procedure}
Let $X = x_1, ..., x_N$ be a standardized time series of length $N \geq 1$. The Persist uses a decision criterion, namely the persistence score described below, to compute the best breakpoints based on this decision criterion for discretizing $X$ \cite{Persist}. \newline
The first step is to determine an ascending sorted list of $l \geq 1$ candidate breakpoints $B := (\beta_j \mid j \in \{1, ..., l\})$ from which the Persist selects the best \cite{Persist}. In the literature, equal frequency binning of the points of $X$ with a default value of 100 bins (i.e. $l = 99$) is proposed to obtain the percentiles of the time series points as candidate breakpoints \cite{Persist}. Taking these percentiles as candidate breakpoints results in a finer sampling in regions with relatively many points compared to a coarser sampling in regions with relatively few points. \newline
Now, let $A := \{\alpha_j \mid j \in \{1, ..., a\}\}$ be the alphabet used for discretizing $X$ based on $a \geq 2$ alphabet symbols (e.g. letters from the Latin alphabet). Then, the second step is to define a discretization function $f: X \times (2^B \setminus ()) \rightarrow A$ that discretizes all time series points of $X$ given a sorted list of $1 \leq k \leq l$ breakpoints from $B$ \cite{Persist}. Such a discretization function $f$ could be defined, for example, based on the \ac{SAX} discretization described by Equation \ref{eq:SAX_Discretization}, where the original time series points of $X$ instead of the means of its \ac{PAA} representation are used. \newline
Based on these two initial steps, the Persist algorithm shown in Algorithm \ref{alg:Persist} builds up the ascending sorted list of best breakpoints iteratively by selecting one of the candidate breakpoints in $B$ in each of the $a-1$ iterations \cite{Persist}. In each iteration, it adds all available candidate breakpoints in $B$ individually to the current list of best breakpoints. Based on this extended list of breakpoints, it computes the persistence score by applying the discretization function $f$ on $X$. Then, the candidate breakpoint with the highest persistence score is added to the current list of best breakpoints and the next iteration starts.
\begin{center}
\begin{algorithm}[H]
  \SetAlgoLined
  \LinesNumbered
  \DontPrintSemicolon
  \KwIn{$X = x_1, ..., x_N$ \tcp*[f]{standardized time series of length $N \geq 1$} \newline
  		$B = (\beta_j \mid j \in \{1, ..., l\})$ \tcp*[f]{$l \geq 1$ candidate breakpoints} \newline
  		$f$ \tcp*[f]{discretization function} \newline
  		$a$ \tcp*[f]{alphabet size $a \geq 2$}}
  \KwOut{$B^*$ \tcp*[f]{ascending sorted breakpoints}}
  
  $B^* \leftarrow ()$\; 
    
  \For{$i \leftarrow 1$ \KwTo $a-1$}{
  	$P \leftarrow ()$ \tcp*[f]{persistence scores}\;
  	\ForEach{$\beta \in B$}{
  		$\hat{X} \leftarrow f(X,B^* \cup (\beta))$ \tcp*[f]{discretized time series}\;
  		$P \leftarrow P \cup (Persistence(\hat{X}))$\;
  	}
  	$j^* \leftarrow argmax(P)$\;
  	$B^* \leftarrow B^* \cup (\beta_{j^*})$ \tcp*[f]{breakpoint with highest persistence score}\;
  	$B \leftarrow B \setminus (\beta_{j^*})$\;
  }
  return $B^*$\;
  
  \caption[Persist - Breakpoints]{The Persist computes the best breakpoints for discretizing $X$ based on a decision criterion called persistence score that is described below \cite{Persist}. Note that selecting breakpoints that are near to each other can be avoided by additionally excluding $r \geq 1$ of the available adjacent breakpoints of each $\beta_{j^*}$ in line 10 of this algorithm \cite{Persist}.}
  \label{alg:Persist}
\end{algorithm}
\end{center}
\subsection*{Persistence Score}
Define $A := \{\alpha_j \mid j \in \{1, ..., a\}\}$ as an alphabet with $a \geq 2$ alphabet symbols (e.g. letters from the Latin alphabet). Assume that $\hat{X} = \hat{x}_1, ..., \hat{x}_n$ is a discretized time series of length $n \geq 1$, where $\hat{x}_i \in A \ (1 \leq i \leq n)$. Let $p(\alpha_j) \ (1 \leq j \leq a)$ be the marginal probability of the alphabet symbol $\alpha_j$ in $\hat{X}$. Further, the $a \times a$ matrix containing the transition probabilities with respect to the alphabet symbols in $\hat{X}$ shall be represented by \mbox{$M(j,k) = p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1} = \alpha_k)$} \cite{Persist}. In this matrix, the self-transition probabilities $p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1} = \alpha_j)$ are the values on the main diagonal $M(j,j)$. \newline
Now, the first case to consider is when the time series does not have any temporal structure \cite{Persist}. Then, the alphabet symbols $\alpha_j$ of $\hat{X}$ can be interpreted as they were generated by a random variable based on the marginal probabilites $p(\alpha_j)$. Thus, the probability of observing a symbol at a point in time in $\hat{X}$ does not depend on the previous symbol. Therefore, the transition probabilities become $M(j,k) = p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1} = \alpha_k) = p(\alpha_j)$ the marginal probabilities. \newline
The other case to consider is a temporal structure described by a first order Markov model \cite{Persist}. In this model, the probability of observing an alphabet symbol $\alpha_j$ at a point in time in $\hat{X}$ depends on the previous symbol. Hence, this probability is described by the transition probability $p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1})$. \newline
The comparison of these two cases is used to measure the persistence of the time series $\hat{X}$ \cite{Persist}. Without any temporal structure in this time series, the transition probabilities of the Markov model $p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1})$ are expected to not deviate too much from the corresponding marginal probabilities $p(\alpha_j)$, since there is no dependence on the previous symbol. \newline
On the other hand, when the time series has a temporal structure, there are two cases \cite{Persist}. First, larger self-transition probabilities $p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1} = \alpha_j)$ than corresponding marginal probabilities $p(\alpha_j)$ indicate a persisting behavior of the time series. Second, lower self-transition probabilities than corresponding marginal probabilities at a point in time indicate that the next alphabet symbol in the time series is more likely than unlikely to be different compared to the current symbol. \newline
Note that the Persist does not assume the time series $\hat{X}$ to be generated by a first order Markov model \cite{Persist}. Only the self-transition probabilities based on this model are used as an indicator for a persisting behavior of the time series. \newline
Thus, the self-transition probabilities $p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1} = \alpha_j)$ as well as the corresponding marginal probabilities $p(\alpha_j)$ are of importance for measuring the persistence of the time series $\hat{X}$ \cite{Persist}. Based on these probabilities, two discrete probability distributions for each alphabet symbol $\alpha_j$ are created \cite{Persist}. The first distribution for alphabet symbol $\alpha_j$ is based on the self-transition probability $M(j,j) = p(\hat{x}_i = \alpha_j \mid \hat{x}_{i-1} = \alpha_j)$ and the complementary probability $M(j,j)^c := 1 - M(j,j)$. Hence, define this distribution as $P_j := \{M(j,j), M(j,j)^c\}$. The second distribution for alphabet symbol $\alpha_j$ is based on the marginal probability $p(\alpha_j)$ and the complementary probability $p(\alpha_j)^c := 1 - p(\alpha_j)$. Hence, define this distribution as $Q_j := \{p(\alpha_j), p(\alpha_j)^c\}$. \newline
Based on the two discrete probability distributions $P_j$ and $Q_j$, the persistence score for each alphabet symbol $\alpha_j$ is computed by \cite{Persist}:
\begin{equation}
Persistence(\alpha_j) := sgn(M(j,j)-p(\alpha_j)) \cdot SKL(P_j,Q_j),
\label{eq:persistence_symbol}
\end{equation}
where $SKL$ is the symmetric Kullback-Leibler divergence and $sgn$ is the sign function. Alphabet symbols $\alpha_j$ with larger self-transition probabilities $M(j,j)$ than corresponding marginal probabilities $p(\alpha_j)$ are assigned a positive persistence score, while alphabet symbols with lower self-transition probabilities than corresponding marginal probabilities are assigned a negative persistence score, since in these cases it is $SKL > 0$. Further, it is $Persistence(\alpha_j) = 0$ if and only if the corresponding discrete probability distributions $P_j$ and $Q_j$ are equal \cite{Persist} (see Figure \ref{fig:symmetric_kl}). \newline
The final persistence score for $\hat{X}$ used in the Persist is then defined by the mean persistence score across all alphabet symbols \cite{Persist}:
\begin{equation}
Persistence(\hat{X}) := \frac{1}{a} \sum_{j=1}^{a} Persistence(\alpha_j)
\label{eq:persistence}
\end{equation}
Remember that the higher the persistence score of a discretized time series the longer the time intervals containing only one alphabet symbol. Thus, for a discretized time series to increase the likelihood of observing the same alphabet symbol at any point in time as for the previous point in time, almost all alphabet symbols need to have high persistence scores, since the mean persistence score is computed \cite{Persist}.
\begin{figure}[htb]
\centering
\includegraphics[scale=0.5]{discretization/persist/symmetric_kl.pdf}
\caption[Persist - Symmetric Kullback-Leibler Divergence]{On the left, exemplary discrete probability distributions $P_j$ and $Q_j$ for alphabet symbol $\alpha_j$ are plotted. On the right, the value of the symmetric Kullback-Leibler divergence of two discrete probability distributions $P = \{p,1-p\}$ and $Q = \{q,1-q\}$ for any $0 < p,q < 1$ is plotted \cite{Persist}. This value increases the greater the distance $|p-q|$ becomes and is zero if and only if $p = q$ holds.}
\label{fig:symmetric_kl}
\end{figure}
\subsection*{Considerations for Implementing the Persistence Score}
Maximum likelihood estimators for the marginal probabilities and the transition probabilities in the matrix $M$ can be obtained by counting the number of alphabet symbols in $\hat{X}$ \cite{Persist}. For example, for the marginal probability $p(\alpha_j)$ this involves counting the occurrences of alphabet symbol $\alpha_j$ in $\hat{X}$. For the transition probability $M(j,k) = p(\alpha_j \mid \alpha_k)$ this involves counting the number of times $\alpha_j$ follows $\alpha_k$ in $\hat{X}$ (see Figure \ref{fig:transition_matrix}). \newline
However, due to the computation of the (symmetric) Kullback-Leibler divergence, a problem arises if there is any $\alpha_j$ where $M(j,j) = p(\alpha_j \mid \alpha_j) = 0$ holds, because the Kullback-Leibler divergence is not defined if any probability used is zero \cite{Persist}. $M(j,j) = 0$ can happen if $\alpha_j$ never follows itself in $\hat{X}$. Note that for the marginal probabilities involved in the computation of the Kullback-Leibler divergence,  $0 < p(\alpha_j) < 1$ holds for any $\alpha_j$ in the Persist, because every discretization interval contains at least one original time series point \cite{Persist}. \newline
For cases with $M(j,j) = 0$, a small value $\epsilon > 0$ (e.g. $n^{-1}$) can be added to $M(j,j)$ and subtracted from the complementary probability $M(j,j)^c = 1 - M(j,j)$ \cite{Persist}. As long as the smallest observed probability $> 0$ used in the computation of the Kullback-Leibler divergence is larger than $\epsilon$, the persistence score can still be used as the decision criterion in the Persist \cite{Persist}.
\begin{figure}[htb]
\centering
\includegraphics[scale=0.5]{discretization/persist/transition_matrix.pdf}
\caption[Persist - Transition Probability Matrix]{This is the transition probability matrix for the discretized time series \mbox{$\hat{X}$ = \textcolor{red}{acbaaaccbbacccccba}}. The self-transition probabilities are the values on the main diagonal \cite{Persist}. For example, $M($\textcolor{red}{a}$,$\textcolor{red}{a}$) = p($\textcolor{red}{a}$\mid$\textcolor{red}{a}$)$ = 0.40 is the result of dividing two occurrences in $\hat{X}$ where \textcolor{red}{a} follows \textcolor{red}{a} by five occurences where \textcolor{red}{a} is followed by any alphabet symbol (including \textcolor{red}{a}).}
\label{fig:transition_matrix}
\end{figure}
\subsection*{Modifications}
In the literature, the Persist is presented to discretize the original points of the standardized time series $X$, rather than the means $\overline{x}_i \ (1 \leq i \leq n)$ of the corresponding \ac{PAA} representation $\overline{X} = \overline{x}_1, ..., \overline{x}_n$, where $1 \leq n \leq N$ \cite{Persist}. While this version of the Persist can also be interpreted as the discretization of the \ac{PAA} representation based on a window length of $w = 1$, a modified version based on a window length of $w > 1$ could be applied. \newline
With such a modified version, the input for Algorithm \ref{alg:Persist} would be the \ac{PAA} representation $\overline{X}$ instead of the original standardized time series $X$. Moreover, in line 5, $\overline{X}$ instead of $X$ would be discretized. Applying this modified version, the Persist would be more time-efficient, because from the window length of $w > 1$ it follows $n < N$. Therefore, the time complexity of the discretization in line 5 would reduce from $\mathcal{O}(N)$ to $\mathcal{O}(n)$ based on the time complexity considerations below. \newline
Moreover, the \ac{PAA} representation $\overline{X}$ could also be used for computing the candidate breakpoints $B$ used for initializing Algorithm \ref{alg:Persist}. Instead of computing the percentiles of the points of $X$, the percentiles of the means of $\overline{X}$ could be computed and used as candidate breakpoints. This would reduce the time complexity of the initialization of the Persist from $\mathcal{O}(N \cdot log_{2}(N))$ to $\mathcal{O}(n \cdot log_{2}(n))$ based on the time complexity considerations below.
\subsection*{Unsupervised Discretization}
Similar to the \ac{aSAX}, the Persist can also be used for unsupervised discretization \cite{Persist}. In the first place, this means that the alphabet size $a$ is no longer an input parameter of the Persist, but can be determined intrinsically. Secondly, when using the unmodified version of the Persist, the need for the window length as an input parameter is eliminated as well, since the \ac{PAA} representation is not needed for both finding candidate breakpoints and discretization. Thus, with these two considerations, it is possible to discretize time series based on the Persist without providing any input parameter. \newline
In comparison to the \ac{aSAX}, the Persist uses the persistence score instead of a clustering evaluation metric like the \ac{SSE} as a decision criterion for determining the alphabet size intrinsically \cite{Persist}. Let $A^* := (a_{min}, ..., a_{max})$ be an ascending sorted list of different alphabet sizes, where $a_{min} \geq 2$ is the minimum and $a_{max} \geq a_{min}$ is the maximum alphabet size. Then, Algorithm \ref{alg:Persist} can be run for each alphabet size in $A^*$ while computing the persistence score for the corresponding resulting discretization. This way, the best alphabet size $a^* \in A^*$ is the one that was used for the resulting discretization that achieved the highest persistence score \cite{Persist}. Thus, the breakpoints that were computed for the alphabet size $a^*$ can then be used for discretizing the respective time series (see Figure \ref{fig:unsupervised_persist}).
\newpage
\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{discretization/persist/persist_unsupervised.pdf}
\caption[Persist - Unsupervised Discretization]{The time series in the left plot is a pattern that is repeated 5 times. The pattern is composed of 5 + 10 + 5 + 5 points drawn from $\mathcal{N}(0,0.3)$, $\mathcal{N}(2,0.4)$, $\mathcal{N}(0,0.3)$, and $\mathcal{N}(-2,0.2)$, respectively, with a subsequent standardization of the composed time series. Then, the Persist shown in Algorithm \ref{alg:Persist} is run for different alphabet sizes $a \in (2, ..., 10)$. The corresponding values of the persistence score are shown in the right plot. Based on the persistence score, the plotted time series should be discretized using an alphabet size of $a^* = 3$. The corresponding breakpoints for discretization in the left plot are adapted to the three different distributions the time series points were drawn from.}
\label{fig:unsupervised_persist}
\end{figure}
\subsection*{Time Complexity}
For the initialization of the Persist without any modifications, the candidate breakpoints $B$ need to be computed as the percentiles of the points of the time series $X$. Sorting these points can be done in $\mathcal{O}(N \cdot log_{2}(N))$. The subsequent retrieval of each of the fixed number of percentiles needs constant time. Therefore, the time complexity for this initialization step is $\mathcal{O}(N \cdot log_{2}(N))$. \newline
Starting at line 4 in Algorithm \ref{alg:Persist}, all available candidate breakpoints in $B$ are iterated.
The first step in such an iteration involves adding the current candidate breakpoint to the sorted list of current best breakpoints $B^*$. This can be done with a binary search in $\mathcal{O}(log_{2}(a-1)) = \mathcal{O}(1)$ for a fixed alphabet size $a \geq 2$, as it is $|B^*| \leq a-1$. \newline
The next step in such an iteration is to discretize $X$ based on the \ac{SAX} discretization described by Equation \ref{eq:SAX_Discretization} and the previously extended list of current best breakpoints. As described for the \ac{SAX}, the time complexity of this discretization step is $\mathcal{O}(N \cdot log_{2}(a-1)) = \mathcal{O}(N)$. \newline
Based on the resulting discretized time series $\hat{X}$, the next step is to compute the persistence score. As described above, this first involves counting the number of alphabet symbols in $\hat{X}$ to compute the marginal and transition probabilities. This can be done by iterating in $\mathcal{O}(N)$. Then for each alphabet symbol in $\hat{X}$, the persistence score based on the symmetric Kullback-Leibler divergence of the two described discrete probability distributions $P$ and $Q$ needs to be computed. The total time complexity for this computation is $\mathcal{O}(a \cdot 2) = \mathcal{O}(1)$ as both probability distribution have two possible outcomes and $|B^*| \leq a-1$. Taking the mean of the persistence scores of the alphabet symbols results in the persistence score of $\hat{X}$ and has a time complexity of $\mathcal{O}(a) = \mathcal{O}(1)$. The persistence score of $\hat{X}$ can then be appended to the previously computed persistence scores in constant time. All in all, the computation of the persistence score of $\hat{X}$ is dominated by counting the number of alphabet symbols in $\hat{X}$, which results in a time complexity of $\mathcal{O}(N)$. \newline
Thus, the time complexity of an iteration for a candidate breakpoint in $B$ is $\mathcal{O}(1) + \mathcal{O}(N) + \mathcal{O}(N) = \mathcal{O}(N)$. Therefore, iterating over a fixed number of $|B|$ candidate breakpoints has a time complexity of $\mathcal{O}(|B| \cdot N) = \mathcal{O}(N)$ \newline
Starting at line 8 in Algorithm \ref{alg:Persist}, the last step is to find the candidate breakpoint that results in the highest persistence score. This can be done by iterating over the persistence scores that correspond to the available candidate breakpoints. Hence, the time complexity is $\mathcal{O}(|B|) = \mathcal{O}(1)$. \newline
All in all, iteratively finding the best $a-1$ breakpoints according to the persistence score with Algorithm \ref{alg:Persist}, results in a total time complexity of $\mathcal{O}((a-1) \cdot N) = \mathcal{O}(N)$ for the Persist without any modifications and the initialization step \cite{Persist}. Taking the initialization step into account, results in a total time complexity of $\mathcal{O}(N \cdot log_{2}(N)) + \mathcal{O}(N) = \mathcal{O}(N \cdot log_{2}(N))$ for the Persist without any modifications.